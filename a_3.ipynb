{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Settings of SVM\n",
    "\n",
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# change paths if necessary\n",
    "TRAIN_SET_PATH = './StanceDataset/train.csv'\n",
    "TEST_SET_PATH = './StanceDataset/test.csv'\n",
    "TRAIN_FEATURE_PATH = 'clean_train_vec.npy'\n",
    "TEST_FEATURE_PATH = 'clean_test_vec.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load (2914,) targets of training data,\n",
      "\t(1956,) features of test data.\n",
      "\n",
      "Load (2914, 13459) features of training data,\n",
      "\t(1956, 13459) features of test data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dictionaries for label encoding and decoding\n",
    "encode_dict = {'Hillary Clinton': 0, 'Climate Change is a Real Concern': 1, 'Legalization of Abortion': 2, 'Atheism': 3, 'Feminist Movement': 4, 'Donald Trump': 5}\n",
    "decode_dict = {0: 'Hillary Clinton', 1: 'Climate Change is a Real Concern', 2: 'Legalization of Abortion', 3: 'Atheism', 4: 'Feminist Movement', 5: 'Donald Trump'}\n",
    "\n",
    "# Load the labels and features\n",
    "# Yuhui: There is no 'Donald Trump' in training data\n",
    "df_train = pd.read_csv(TRAIN_SET_PATH, engine='python', dtype='str', encoding ='latin1')\n",
    "df_test = pd.read_csv(TEST_SET_PATH, engine='python', dtype='str', encoding ='latin1')\n",
    "Y_train = np.array([encode_dict[t] for t in df_train['Target']])\n",
    "Y_test = np.array([encode_dict[t] for t in df_test['Target']])\n",
    "print(\"Load {} targets of training data,\\n\\t{} features of test data.\\n\".format(Y_train.shape, Y_test.shape))\n",
    "\n",
    "X_train = np.load(TRAIN_FEATURE_PATH)\n",
    "X_test = np.load(TEST_FEATURE_PATH)\n",
    "print(\"Load {} features of training data,\\n\\t{} features of test data.\\n\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.40081799591002043\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=1.0, kernel='rbf', decision_function_shape='ovr', class_weight=None)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regularization parameter\n",
    "\n",
    "**C: float, default=1.0**\n",
    "\n",
    "Refer: [Intuition for the regularization parameter in SVM](https://datascience.stackexchange.com/questions/4943/intuition-for-the-regularization-parameter-in-svm)\n",
    "\n",
    "The regularization parameter (lambda) serves as a degree of importance that is given to misclassifications. SVM poses a quadratic optimization problem that looks for maximizing the margin between both classes and minimizing the number of misclassifications. However, for non-separable problems, in order to find a solution, the misclassification constraint must be relaxed, and this is done by setting the mentioned \"regularization\". \n",
    "\n",
    "If the regularization parameter is too small, the model will be underfitted. If the regularization parameter is too large, the model will be overfitted. \n",
    "\n",
    "### 2.1 C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.21063394683026584\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=0.1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.4212678936605317\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 C = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.4212678936605317\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=100)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kernel type\n",
    "\n",
    "**kernel: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’**\n",
    "\n",
    "Related parameters: \n",
    "\n",
    "- **degree: int, default=3**\n",
    "- **gamma: {‘scale’, ‘auto’} or float, default=’scale’**\n",
    "- **coef0: float, default=0.0**\n",
    "\n",
    "### 3.1 kernel = 'linear'\n",
    "\n",
    "$$K(x_i,x_j)=x_i^Tx_j$$\n",
    "\n",
    "As the above equation shows, the linear kernel does not need other parameters. According to the experience, in this experiment, the feature for each sentence is large enough, the data may be linearly separable by mapping it to higher dimensions. In intuit, the linear kernel may get great results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 kernel = 'poly'\n",
    "\n",
    "$$K(x_i,x_j)=(\\gamma x_i^Tx_j + r)^d, d>1$$\n",
    "\n",
    "As the above equation shows, the polynomial kernel need 3 parameters, $d$, $\\gamma$, $r$. In this experiment, the feature of each sentence is large, the linear kernel is enough to classify the data, so we do not need a polynomial kernel with slow training. \n",
    "\n",
    "### 3.3 kernel = 'rbf'\n",
    "\n",
    "$$K(x_i,x_j)=exp(-\\gamma ||x_i-x_j||^2),\\gamma>0$$\n",
    "\n",
    "As the above equation shows, the radial basis function (RBF) kernel need 1 parameters, $\\gamma$. Let's ajust $\\gamma$. \n",
    "\n",
    "The larger the gamma, the fewer support vectors, and the smaller the gamma value, the more support vectors. More support vectors could fit the model better for the training data, however, may lead to a bad performance on test data. Here, we only try 'scale' and 'auto' of $\\gamma$ rather than other float numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.15081799591002046\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 kernel = 'sigmoid'\n",
    "\n",
    "$$K(x_i,x_j)=tanh(\\gamma x_i^Tx_j + r ), \\gamma>0, r<0$$\n",
    "\n",
    "As the above equation shows, the sigmoid kernel need 2 parameters, $\\gamma$, $r$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.4120654396728016\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(kernel='sigmoid')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.15081799591002046\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(kernel='sigmoid', gamma='auto')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class weight of regularization parameter\n",
    "\n",
    "**class_weight: dict or ‘balanced’, default=None**\n",
    "\n",
    "This parameter could set the regularization parameter `C` of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The ‘balanced’ mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y))`. Let's try ‘balanced’ mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.401840490797546\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best settings\n",
    "\n",
    "From all the experiments above, we know that linear kernel and balanced class weight have a positive effect on the results. However, the regularization parameter changes when using different kernels, and it can not be too large or too small. Then we will check the different regularization parameters (`C=10`, `C=1`, `C=5`, `C=2.5`, `C=1.25`, `C=0.625`). In the end, we get the best settings as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42535787321063395\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=1, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=10, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=5, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=2.5, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.42484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=1.25, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM...\n",
      "Done!\n",
      "Let's test the SVM!\n",
      "Accuracy score: 0.4279141104294479\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print(\"Training the SVM...\")\n",
    "clf = svm.SVC(C=0.625, kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Test\n",
    "print(\"Let's test the SVM!\")\n",
    "Y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy score: {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36ae728f10cb4a9fb53c3fd03aaea402af50bd5d5f009e385e6fbcc34fa73efc"
  },
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
